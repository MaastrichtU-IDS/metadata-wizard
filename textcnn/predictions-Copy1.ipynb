{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "\n",
    "import csv,pandas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data helpers - copied from https://github.com/bhaveshoswal/CNN-text-classification-keras\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for datasets.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the unique number of diseases are 540\n",
      " the unique number of class are 7\n"
     ]
    }
   ],
   "source": [
    "diseasesName, diseasesClass  = [],[]\n",
    "with open('NCBItrainset.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        diseasesName.append(row[0])\n",
    "        diseasesClass.append(row[1])\n",
    "\n",
    "diseasesName, diseasesClass = diseasesName[1:], diseasesClass[1:]\n",
    "\n",
    "if debug:\n",
    "    print(f\" the unique number of diseases are {len(list(set(diseasesName)))}\")\n",
    "    print(f\" the unique number of classes are {len(list(set(diseasesClass)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt') as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "content = [x.strip() for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv('hrdata.csv')\n",
    "data = [x for x in df.to_records(index=False)] \n",
    "def read_till_next(data,index):\n",
    "    temp = []\n",
    "    temp_loc = 0\n",
    "    for d in data[index+1:]:\n",
    "        if 'a' in d[1] or 't' in d[1]:\n",
    "            return temp,temp_loc\n",
    "        else:\n",
    "            temp_loc = temp_loc + 1\n",
    "            temp.append([d[2],d[3],d[4]])\n",
    "    \n",
    "    return temp,temp_loc\n",
    "\n",
    "loc = 0\n",
    "final_data = []\n",
    "for index,d in enumerate(data):\n",
    "    if '|t|' in d[1]:\n",
    "        continue\n",
    "    elif loc != 0:\n",
    "        loc = loc - 1\n",
    "        continue\n",
    "    else:\n",
    "        if '|a|' in d[1]:\n",
    "            temp_holder = {\n",
    "                'abstract' : d[1],\n",
    "                'keys' : []\n",
    "            }\n",
    "            keys,loc = read_till_next(data,index)\n",
    "            temp_holder['keys'] = keys\n",
    "            final_data.append(temp_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1301"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diseasesName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
